---
title: "Wait Times for Repairs"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
library(ggplot2)
```

*From Hesterberg's article "What Teachers Should Know about the Bootstrap: Resampling in the Undergraduate Statistics Curriculum"*


# Introduction

The New York Public Utilities Commission monitors the response time
for repairing land-line phone service in the state.  These repair
times may differ over the year and according to the type of repair.
We have repair times for one class of repairs at one time period.  The
commission is interested in estimates of the average repair time.

### Read in the data 


Read in the data provided in `data/ilec.csv`.

```{r}
repair = read.csv("../data/ilec.csv", header = FALSE)
names(repair) = "wait_time"
head(repair)

```


### Explore the distribution of repair time

Before making any estimates of average repair time, we examine the data values. 

```{r}
ggplot(repair, aes(x = wait_time)) +
  geom_histogram(aes(y = ..density..), bins = 40)
```

We see that there is a spike at 0, which indicates that
many repairs happen immediately. We also see two modes (not counting the spike). Furthermore, the distribution is skewed right with a long tail indicating that a few repairs take a long time.

Let's plot this on log10 scale for a better view. When taking logs, use base 10. When there are 0 values, we often add 1 before taking the log.

```{r}
ggplot(repair, aes(x = (1+ wait_time))) +
  geom_histogram(aes(y = ..density..), bins = 40) +
  scale_x_log10() +
  labs(x = "Time to Repair (log hours + 1) ")
```

This plot makes it very clear that there is a spike at 0 (we added 1 in order to take the log), and in addition there are two main modes.
The second mode is centered near $24$, which indicates that many repairs occur then next day. 


```{r}
n = length(repair$wait_time)
n
avg_time = mean(repair$wait_time)
avg_time
sd_time = sd(repair$wait_time)
sd_time
```




## Normal Theory confidence intervals

If we assume that the sampling distribution of the mean is normally distributed, then we can use this property to create a confidence interval.

For a standard normal, which is centered at 0 and has a spread of 1, we can find the quantiles with `qnorm'

```{r}
qnorm(c(0.025, 0.975))
```

We standardize our sample mean, i.e., 
$$\frac{\hat{\theta} - \theta} {SE({\hat{\theta}})}$$
and use the normal quantiles to create a confidence interval for $\theta$, i.e., 

```{r}
se_avg_time = sd_time/sqrt(n)

normal_CI = c(lower = avg_time - qnorm(0.975) * se_avg_time, 
              upper = avg_time - qnorm(0.025) * se_avg_time)

normal_CI
```


When bootstrapping was computationally infeasible, we relied heavily on the Central Limit Theorem to form confidence intervals for the population. Of course, an important question is whether $n$ is large enough to justify the assumption that that the CLT holds and we can treat our sample statistic as normally distributed.


 
## Percentile Bootstrap  

One approach to bootstrapping a confidence interval is the percentile bootstrap. We find the bootstrap sampling distribution of the sample mean using 10,000 replicates. 

```{r}
set.seed(2461)
bootMeans = 
  replicate(100000, mean(sample(repair$wait_time, n, replace = TRUE)) )
```

Make a histogram of the bootstrapped means. Does the bootstrapped sampling distribution of the mean look symmetric? Roughly normal?

```{r}
ggplot(data.frame(means = bootMeans),
       aes(x = means)) +
  geom_histogram(aes(y = ..density..), bins = 40) +
  labs(x = "Bootstrapped Sampling Distribution of mean Time to Repair")

```


The percentile bootstrap confidence interval consiste of the 2.5 and 97.5 percentile of the bootstrapped distribution of the sample mean. 

```{r}
boot_percentile_CI = quantile(bootMeans, 
                              probs = c(0.025, 0.975))
names(boot_percentile_CI) = c("lower", "upper")
boot_percentile_CI
```


## The Studentized Bootstrap
 
One variation on the bootstrap confidence interval uses the approach of standardizing the statistic from normal theory confidence intervals. This variation finds the bootstrap sampling distribution of the standardized statistic, i.e.,
$$ \frac{\hat{\theta} - \theta} {SE({\hat{\theta}})}$$
And, we use the percentiles of this bootstrap distribution to create the confidence interval.


In the case of the mean, for each bootstrap sample, we find the standardized statistic:
$$ \frac{\hat{\theta^*} - \hat{\theta}} {SD({\hat{\theta^*})/\sqrt{n}}}$$
(The original sample mean is the population mean in this situation.)

Our confidence interval is then:
$$\left(\hat{\theta} - q^*_{0.975}SE({\hat{\theta}}), ~ \hat{\theta} - q^*_{0.025}SE({\hat{\theta}})\right)$$
Here, $q^*$ is the 2.5 and 97.5 percentile of the distribution of the bootstrapped standardized statistic. Note that we have not used any normal theory or central limit theorem here. We have simply created a confidence interval based on the sampling distribution of the standardized statistic.


Computing this bootstrapped standardized statistic requires estimating the SE of each bootstrap statistic. For the case of the sample mean, we simply need to compute the SD of the bootstrap sample in addition to the mean.

```{r}
set.seed(2461)
bootStats = 
  replicate(100000, {
    bootSample = sample(repair$wait_time, n, replace = TRUE)
    c(mean(bootSample), sd(bootSample))
  })
```

The return value is a matrix, which we turn into a data frame.
```{r}
bootStatsDF = data.frame(means = bootStats[1,], 
                         sds = bootStats[2,])
```


We estimate $q^*_{0.025}$ and $q^*_{0.975}$ from these bootstrap replicates and create the confidence interval.

```{r}
student_boot = (bootStatsDF$means - avg_time)/ (bootStatsDF$sd/sqrt(n))

student_boot_CI = avg_time - quantile(student_boot, 
                                      probs = c(0.975, 0.025))
names(student_boot_CI) = c("lower", "upper")
student_boot_CI
```


## Comparison of confidence intervals

Compare the three confidence intervals: normal-theory, bootstrap percentile, and studentized bootstrap.

```{r}
normal_CI 
boot_percentile_CI 
student_boot_CI 
```

Notice how much larger the studentized bootstrap confidence interval is.

We also find the distance from the endpoints of the intervals to the sample mean. 

```{r}
normal_CI - avg_time
boot_percentile_CI - avg_time
student_boot_CI - avg_time
```

Notice how the bootstrap percentile interval is asymmetric with the asymmetry in the same direction as the data. The same is the case for the studentized bootstrap, but even more so.

Compare the ratio of these two distances to get a sense of the size of the asymmetry

```{r}
(normal_CI[2] - avg_time) / (avg_time - normal_CI[1])
(boot_percentile_CI[2] - avg_time) / (avg_time -
                                        boot_percentile_CI[1])
(student_boot_CI[2] - avg_time) / (avg_time - student_boot_CI[1])
```


Note that when the bootstrap sample is larger than the sample mean, the bootstrap SD also tends to be large. We can confirm this via 
the positive correlation between the bootstrapped mean and it's SD.
```{r}
cor(bootStatsDF$means, bootStatsDF$sds)
```

Also, make a scatter plot of the pairs of the bootstrapped mean and SD. 

```{r}
ggplot(bootStatsDF,
       aes(x = means, y = sds)) +
  geom_point(alpha = 0.02) +
  labs(x = "Bootstrapped means", y= "Bootstrapped SDs")
```

The studentized bootstrap tends to provide more accurate coverage when the distribution is highly skewed and the sample size is large.
